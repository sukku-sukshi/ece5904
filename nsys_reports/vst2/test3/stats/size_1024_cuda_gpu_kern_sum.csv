Time (%),Total Time (ns),Instances,Avg (ns),Med (ns),Min (ns),Max (ns),StdDev (ns),Name
14.0,225036028,2836,79349.8,53695.0,29759,317597,41634.5,cudnn_volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f_exp_small_nhwc2nchw_tn_v1
12.3,197895262,18128,10916.6,5696.0,2112,226909,17369.1,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
11.4,183565868,19272,9525.0,4096.0,2624,202590,15215.2,"void cudnn::ops::nchwToNhwcKernel<__half, __half, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::ops::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
8.6,138383703,16821,8226.8,4225.0,2527,170814,13340.2,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
8.0,127739236,4702,27167.0,24800.0,21536,81215,6790.8,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_execute_kernel_cudnn
5.4,87251441,756,115412.0,118783.0,86687,171647,25005.4,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x128x32_stage1_warpsize2x2x1_g1_tensor8x8x4_execute_kernel_cudnn
4.7,74697793,3012,24800.1,19424.0,9312,105279,21475.7,volta_fp16_s884gemm_fp16_64x64_ldg8_f2f_nn
4.1,65004397,1512,42992.3,39440.0,7360,183295,31598.7,"void at::native::<unnamed>::max_pool_forward_nchw<c10::Half, c10::Half>(int, const T1 *, long, long, long, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
3.8,60984939,3213,18980.7,12704.0,6880,110559,14030.0,"void at::native::<unnamed>::CatArrayBatchedCopy<c10::Half, unsigned int, (int)4, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
3.1,49759287,1880,26467.7,27503.0,18816,36864,6418.2,void cutlass::Kernel<cutlass_70_tensorop_f16_s884gemm_relu_f16_64x64_nn_align8>(T1::Params)
3.0,47496367,575,82602.4,83167.0,26847,174527,22367.4,volta_fp16_s884gemm_fp16_256x128_ldg8_f2f_nn
2.8,44288206,377,117475.3,145823.0,87839,149662,28951.2,cudnn_volta_fp16_s884cudnn_fp16_256x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1
2.2,35539696,954,37253.4,30080.0,19360,119711,23306.1,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_execute_kernel_cudnn
1.9,30408047,189,160889.1,160255.0,157950,278174,8625.6,cudnn_volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1
1.6,25267591,7360,3433.1,3072.0,2687,8064,931.5,"void cudnn::ops::nhwcToNchwKernel<__half, __half, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
1.3,21536245,760,28337.2,21408.0,21280,70880,11864.1,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize128x64x32_stage1_warpsize2x2x1_g1_tensor8x8x4_execute_kernel_cudnn
1.3,21364720,194,110127.4,110271.0,84063,193278,7165.8,cudnn_volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_small_nhwc2nchw_tn_v1
1.0,15727566,376,41828.6,41967.0,32031,51552,8703.4,volta_fp16_s884gemm_fp16_64x128_ldg8_f2f_nn
0.9,14624686,188,77790.9,77855.0,73791,79167,510.7,sm70_xmma_fprop_implicit_gemm_indexed_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_execute_kernel_cudnn
0.8,13041956,2059,6334.1,3200.0,1952,54432,8917.0,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.6,9850722,3597,2738.6,2464.0,1919,11872,1195.2,"void cask_cudnn::computeOffsetsKernel<(bool)0, (bool)0>(cask_cudnn::ComputeOffsetsParams)"
0.6,9618051,188,51159.8,51103.5,49504,53023,740.0,void cutlass::Kernel<cutlass_70_tensorop_f16_s884gemm_relu_f16_128x128_nn_align8>(T1::Params)
0.4,6776985,189,35857.1,35808.0,34848,37056,440.7,"void tensorTransformGeneric<__half, __half, float, (bool)1, (bool)0, (bool)0, (cudnnKernelDataType_t)0>(cudnnTensorTransformStruct, tensorTransformParams, int, unsigned long, const T1 *, T2 *, T3, T3)"
0.4,6437159,190,33879.8,33328.0,26879,145631,8172.4,volta_fp16_s884gemm_fp16_128x128_ldg8_f2f_nn
0.3,5098163,567,8991.5,7968.0,5823,13376,2796.3,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.3,4606018,1134,4061.7,3456.0,3264,8768,1114.7,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.3,4564113,189,24148.7,23872.0,22816,40320,1343.0,"void at::native::<unnamed>::CatArrayBatchedCopy<c10::Half, unsigned int, (int)3, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
0.3,4080698,567,7197.0,4351.0,2976,23616,4872.7,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::sigmoid_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.3,4064354,567,7168.2,6175.0,4415,11104,2598.8,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.2,3988288,185,21558.3,21568.0,17344,21856,328.0,"void at_cuda_detail::cub::DeviceRadixSortSingleTileKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<float, at_cuda_detail::cub::NullType, int>::Policy800, (bool)0, float, at_cuda_detail::cub::NullType, int>(const T3 *, T3 *, const T4 *, T4 *, T5, int, int)"
0.2,3718063,374,9941.3,14752.0,1920,39775,6190.9,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.2,2999167,752,3988.3,4031.0,3104,5599,822.2,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.2,2907354,740,3928.9,2880.0,2687,10336,1977.2,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.2,2818248,185,15233.8,15232.0,9248,20831,3047.0,"void vision::ops::<unnamed>::nms_kernel_impl<float>(int, double, const T1 *, unsigned long long *)"
0.2,2480145,378,6561.2,7472.0,4960,11903,1531.0,"void at::native::<unnamed>::upsample_nearest2d_out_frame<c10::Half, &at::native::nearest_neighbor_compute_source_index>(const T1 *, T1 *, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, float, float)"
0.2,2439597,189,12907.9,12896.0,12735,15136,182.5,void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align8>(T1::Params)
0.1,2257582,1014,2226.4,2032.0,1855,49503,1530.7,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,2222447,653,3403.4,3328.0,1919,41183,2403.4,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.1,2062798,48,42975.0,33504.0,7744,226717,53330.6,volta_sgemm_128x32_nn
0.1,2016137,474,4253.5,3072.0,2943,6592,1525.6,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<long, at::native::func_wrapper_t<long, at::native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, (int)4>>(T3)"
0.1,1846342,573,3222.2,2720.0,2592,48895,2070.4,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1795720,185,9706.6,9728.0,7680,10432,338.7,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)2>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1706284,740,2305.8,2048.0,2015,3233,440.5,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::<unnamed>::launch_clamp_scalar(at::TensorIteratorBase &, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1705879,740,2305.2,2144.0,2079,3232,313.4,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1598223,141,11334.9,11328.0,9216,11711,216.0,"void at::native::radixSortKVInPlace<(int)-2, (int)-1, (int)32, (int)4, float, long, unsigned int>(at::cuda::detail::TensorInfo<T5, T7>, T7, T7, T7, at::cuda::detail::TensorInfo<T6, T7>, T7, bool)"
0.1,1557963,185,8421.4,8383.0,6624,9312,255.8,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<c10::Half, at::native::MaxOps<c10::Half>, unsigned int, c10::Half, (int)4>>(T3)"
0.1,1544361,370,4173.9,3759.5,2592,5600,1103.2,"void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::DispatchSelectIf<at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, long *, int *, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, (bool)0>::PtxSelectIfPolicyT, at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, long *, int *, at_cuda_detail::cub::ScanTileState<int, (bool)1>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, (bool)0>(T2, T3, T4, T5, T6, T7, T8, T9, int)"
0.1,1507881,185,8150.7,8159.0,8095,8320,38.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,1429521,370,3863.6,2912.5,2143,8160,1798.3,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.1,1317649,370,3561.2,3312.5,2719,4609,816.1,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_put_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIterator &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1234193,185,6671.3,6656.0,5984,7360,183.0,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<void at::native::compare_scalar_kernel<c10::Half>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1113614,474,2349.4,1952.0,1888,3296,511.6,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.1,1112015,474,2346.0,2081.0,2047,3008,333.0,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,1110024,567,1957.7,1792.0,1599,2624,348.6,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,1046711,474,2208.3,1664.0,1599,3264,700.7,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<long>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,1046003,567,1844.8,1760.0,1599,2431,222.8,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::pow_tensor_scalar_kernel_impl<c10::Half, c10::Half>(at::TensorIteratorBase &, T2)::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,984471,15,65631.4,65664.0,23103,136415,33272.5,cudnn_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
0.1,968374,548,1767.1,1728.0,1503,2337,214.0,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,850702,185,4598.4,4608.0,3135,4864,132.2,"void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::DispatchSelectIf<const float *, at_cuda_detail::cub::NullType *, float *, long *, at_cuda_detail::cub::NullType, at_cuda_detail::cub::Equality, int, (bool)0>::PtxSelectIfPolicyT, const float *, at_cuda_detail::cub::NullType *, float *, long *, at_cuda_detail::cub::ScanTileState<int, (bool)1>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::Equality, int, (bool)0>(T2, T3, T4, T5, T6, T7, T8, T9, int)"
0.1,844507,185,4564.9,4544.0,3456,4832,113.0,"void at_cuda_detail::cub::DeviceReduceKernel<at_cuda_detail::cub::DeviceReducePolicy<bool, int, int, at_cuda_detail::cub::Sum>::Policy600, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, int *, int, at_cuda_detail::cub::Sum>(T2, T3, T4, at_cuda_detail::cub::GridEvenShare<T4>, T5)"
0.1,805941,185,4356.4,4352.0,3647,4608,111.2,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,677593,217,3122.5,3265.0,2368,3584,306.3,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,660918,185,3572.5,3552.0,2592,3744,95.9,"void at_cuda_detail::cub::DeviceReduceSingleTileKernel<at_cuda_detail::cub::DeviceReducePolicy<bool, int, int, at_cuda_detail::cub::Sum>::Policy600, int *, int *, int, at_cuda_detail::cub::Sum, int>(T2, T3, T4, T5, T6)"
0.0,656990,185,3551.3,3520.0,2720,3808,103.4,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<c10::Half>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,614773,185,3323.1,3296.0,2495,3488,83.4,"void at_cuda_detail::cub::DeviceReduceSingleTileKernel<at_cuda_detail::cub::DeviceReducePolicy<bool, int, int, at_cuda_detail::cub::Sum>::Policy600, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, int *, int, at_cuda_detail::cub::Sum, int>(T2, T3, T4, T5, T6)"
0.0,594458,18,33025.4,29104.0,26496,48255,7728.9,volta_fp16_s884gemm_fp16_128x64_ldg8_f2f_nn
0.0,587339,185,3174.8,3136.0,2944,3424,74.3,"void at::native::<unnamed>::indexSelectLargeIndex<float, long, unsigned int, (int)2, (int)2, (int)-2, (bool)1>(at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T2, T3>, int, int, T3, T3, long)"
0.0,559134,370,1511.2,1504.0,1312,1824,154.2,"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, (bool)1>, int *>(T1, int, T2)"
0.0,548030,185,2962.3,3040.0,2592,3264,163.5,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::flip_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIterator &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,537245,185,2904.0,3008.0,2560,3232,185.6,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,532311,207,2571.6,1760.0,1535,69663,6834.7,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<float>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.0,525148,185,2838.6,2944.0,2496,3168,184.9,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::round_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,517302,185,2796.2,2752.0,2304,3264,172.0,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.0,421372,3,140457.3,204990.0,11168,205214,111967.9,volta_sgemm_32x128_nn
0.0,378531,44,8603.0,8623.5,7328,8929,219.8,"void at::native::radixSortKVInPlace<(int)-2, (int)-1, (int)16, (int)2, float, long, unsigned int>(at::cuda::detail::TensorInfo<T5, T7>, T7, T7, T7, at::cuda::detail::TensorInfo<T6, T7>, T7, bool)"
0.0,352956,2,176478.0,176478.0,9344,343612,236363.2,"void implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, const T2 *, const T2 *, bool, int, int)"
0.0,352743,184,1917.1,1888.0,1696,3296,173.2,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float>>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.0,349538,182,1920.5,1408.0,1312,24576,2363.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<float>, at::detail::Array<char *, (int)1>>(int, T2, T3)"
0.0,320832,178,1802.4,1760.0,1663,3104,169.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::sqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,315833,185,1707.2,1696.0,1503,1856,42.2,"void <unnamed>::elementwise_kernel_with_index<int, at::native::arange_cuda_out(const c10::Scalar &, const c10::Scalar &, const c10::Scalar &, at::Tensor &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(T1, T2, function_traits<T2>::result_type *)"
0.0,305566,185,1651.7,1632.0,1504,1824,35.9,"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, (bool)1>, long *>(T1, int, T2)"
0.0,282845,33,8571.1,7391.0,6112,17120,3242.6,volta_sgemm_32x32_sliced1x4_nn
0.0,263453,73,3608.9,3136.0,2655,11840,1599.3,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,252190,2,126095.0,126095.0,103103,149087,32515.6,volta_fp16_s884gemm_fp16_256x64_ldg8_f2f_nn
0.0,223101,4,55775.3,60063.0,26688,76287,23717.4,"void implicit_convolve_sgemm<float, float, (int)128, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, const T2 *, const T2 *, bool, int, int)"
0.0,217311,19,11437.4,8895.0,6560,34784,8284.1,volta_sgemm_64x32_sliced1x4_nn
0.0,172862,92,1878.9,1824.0,1727,2688,152.1,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.0,166849,15,11123.3,8832.0,3872,36352,10494.6,"void cudnn::winograd::generateWinogradTilesKernel<(int)0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<T2, T3>)"
0.0,142560,36,3960.0,2880.0,2080,9184,2304.7,"void splitKreduce_kernel<(int)32, (int)16, int, float, float, float, float, (bool)1, (bool)0, (bool)0>(cublasSplitKParams<T6>, const T4 *, const T5 *, T5 *, const T6 *, const T6 *, const T7 *, const T4 *, T7 *, void *, long, T6 *, int *)"
0.0,132350,1,132350.0,132350.0,132350,132350,0.0,cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1
0.0,100479,49,2050.6,1919.0,1760,2656,257.9,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,96478,2,48239.0,48239.0,46847,49631,1968.6,void cutlass::Kernel<cutlass_70_tensorop_f16_s884gemm_relu_f16_128x64_nn_align8>(T1::Params)
0.0,76160,1,76160.0,76160.0,76160,76160,0.0,"void precomputed_convolve_sgemm<float, (int)1024, (int)5, (int)5, (int)4, (int)3, (int)3, (int)1, (bool)0>(int, int, int, const T1 *, int, T1 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, bool, const T1 *, const T1 *, int *)"
0.0,67103,1,67103.0,67103.0,67103,67103,0.0,volta_sgemm_128x64_nn
0.0,65535,9,7281.7,6432.0,3744,12576,2785.7,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,32513,9,3612.6,3648.0,3296,3968,234.9,"void at::native::<unnamed>::CatArrayBatchedCopy<float, unsigned int, (int)4, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
0.0,30206,12,2517.2,2432.0,2399,3168,230.6,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)2, (int)2, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,20257,6,3376.2,3376.0,2528,4352,737.9,"void at::native::<unnamed>::max_pool_forward_nchw<float, float>(int, const T1 *, long, long, long, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
0.0,16064,4,4016.0,4032.0,3232,4768,868.7,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<T1, T2>)"
0.0,14336,4,3584.0,3296.5,3264,4479,596.9,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<T1, T2>)"
0.0,14335,4,3583.8,3536.0,3200,4063,406.9,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<T1, T2>)"
0.0,12608,2,6304.0,6304.0,2752,9856,5023.3,"void cudnn::ops::nchwToNhwcKernel<float, float, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::ops::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
0.0,10687,2,5343.5,5343.5,4479,6208,1222.6,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::MaxNanFunctor<float>>, unsigned int, float, (int)4>>(T3)"
0.0,8415,1,8415.0,8415.0,8415,8415,0.0,"std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, float, float, float, float, (bool)0, (bool)1, (bool)1, (bool)0, (int)8, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)"
0.0,3168,1,3168.0,3168.0,3168,3168,0.0,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)2, (int)4, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,3135,1,3135.0,3135.0,3135,3135,0.0,"void cudnn::ops::nhwcToNchwKernel<float, float, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
0.0,1728,1,1728.0,1728.0,1728,1728,0.0,"void cudnn::cnn::kern_precompute_indices<(bool)0>(int *, int, int, int, int, int)"
