Time (%),Total Time (ns),Instances,Avg (ns),Med (ns),Min (ns),Max (ns),StdDev (ns),Name
23.6,125507832,8128,15441.4,15104.0,10655,37887,3765.5,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x32x64_stage1_warpsize2x1x2_g1_tensor8x8x4_execute_kernel_cudnn
18.9,100194694,17011,5890.0,2944.0,2303,59968,8068.9,"void cudnn::ops::nchwToNhwcKernel<__half, __half, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::ops::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
11.4,60515299,18128,3338.2,3328.0,2111,6336,355.5,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
7.0,37247769,16821,2214.4,2208.0,1856,4320,286.4,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
7.0,36964552,4541,8140.2,8992.0,4607,14880,2258.3,void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align8>(T1::Params)
4.2,22423504,2632,8519.6,7839.5,5440,15680,1917.0,void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align2>(T1::Params)
4.1,21752370,8506,2557.3,2496.0,2144,4992,405.9,"void cudnn::ops::nhwcToNchwKernel<__half, __half, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
2.3,12236576,3213,3808.5,3520.0,3008,6655,742.9,"void at::native::<unnamed>::CatArrayBatchedCopy<c10::Half, unsigned int, (int)4, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
1.8,9512212,1141,8336.7,7360.0,5696,13984,2597.1,volta_fp16_s884gemm_fp16_64x64_ldg8_f2f_nn
1.6,8577856,3401,2522.2,2305.0,2143,4416,386.3,"void splitKreduce_kernel<(int)32, (int)16, int, __half, __half, float, __half, (bool)1, (bool)0, (bool)0>(cublasSplitKParams<T6>, const T4 *, const T5 *, T5 *, const T6 *, const T6 *, const T7 *, const T4 *, T7 *, void *, long, T6 *, int *)"
1.1,5919352,1512,3914.9,3904.0,2816,5696,612.7,"void at::native::<unnamed>::max_pool_forward_nchw<c10::Half, c10::Half>(int, const T1 *, long, long, long, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
1.0,5422339,2059,2633.5,2240.0,1919,5216,845.2,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.9,4738489,189,25071.4,25088.0,18304,25631,525.9,sm70_xmma_fprop_implicit_gemm_f16f16_f16f32_f32_nhwckrsc_nhwc_tilesize64x64x64_stage1_warpsize2x2x1_g1_tensor8x8x4_execute_kernel_cudnn
0.8,4389120,189,23222.9,23264.0,16991,23585,490.9,void cutlass_cudnn::Kernel<cutlass_tensorop_f16_s884fprop_analytic_f16_128x64_32x2_nhwc_align8>(T1::Params)
0.8,4006966,185,21659.3,21695.0,17344,21984,341.3,"void at_cuda_detail::cub::DeviceRadixSortSingleTileKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<float, at_cuda_detail::cub::NullType, int>::Policy800, (bool)0, float, at_cuda_detail::cub::NullType, int>(const T3 *, T3 *, const T4 *, T4 *, T5, int, int)"
0.7,3639948,567,6419.7,4512.0,2720,12448,3915.6,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.6,3384049,1134,2984.2,2880.0,2175,4608,769.5,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.5,2890542,567,5098.0,3679.0,2399,9472,2943.5,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.5,2827053,189,14958.0,15008.0,13888,16160,460.0,"void implicit_convolve_sgemm<__half, __half, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, const T2 *, const T2 *, bool, int, int)"
0.5,2667542,740,3604.8,2863.5,2624,7967,1389.2,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.5,2471436,752,3286.5,2944.0,2176,4833,828.6,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.4,2277369,1010,2254.8,2048.0,1855,48863,1515.8,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.4,2256335,653,3455.3,3329.0,1920,41439,2440.2,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.4,2203726,188,11721.9,11712.0,11424,12096,128.8,void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_32x32_64x2_nn_align1>(T1::Params)
0.4,2146179,185,11601.0,11520.0,4928,15168,1922.1,"void vision::ops::<unnamed>::nms_kernel_impl<float>(int, double, const T1 *, unsigned long long *)"
0.4,2084202,48,43420.9,33887.0,7776,229565,53853.8,volta_sgemm_128x32_nn
0.4,2059924,374,5507.8,6272.0,1951,42144,3140.3,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 10)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.3,1858759,189,9834.7,9825.0,9440,10144,136.3,void cutlass::Kernel<cutlass_70_wmma_tensorop_f16_s161616gemm_f16_16x16_64x2_nn_align8>(T1::Params)
0.3,1704812,740,2303.8,2112.0,2016,3233,378.0,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.3,1687357,732,2305.1,2080.0,2015,3297,424.7,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::<unnamed>::launch_clamp_scalar(at::TensorIteratorBase &, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.3,1629224,567,2873.4,2464.0,2176,4128,775.2,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::sigmoid_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 3)]::operator ()() const::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.3,1623886,185,8777.8,8736.0,7105,9856,347.6,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)2>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.3,1559053,330,4724.4,5952.0,2912,6368,1529.8,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<long, at::native::func_wrapper_t<long, at::native::sum_functor<long, long, long>::operator ()(at::TensorIterator &)::[lambda(long, long) (instance 1)]>, unsigned int, long, (int)4>>(T3)"
0.3,1516269,185,8196.0,8159.0,6560,9312,274.1,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<c10::Half, at::native::MaxOps<c10::Half>, unsigned int, c10::Half, (int)4>>(T3)"
0.3,1512973,573,2640.4,2336.0,1952,49184,2094.8,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.3,1385127,370,3743.6,3296.0,2528,4864,714.5,"void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::DispatchSelectIf<at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, long *, int *, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, (bool)0>::PtxSelectIfPolicyT, at_cuda_detail::cub::CountingInputIterator<long, long>, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, long *, int *, at_cuda_detail::cub::ScanTileState<int, (bool)1>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::NullType, int, (bool)0>(T2, T3, T4, T5, T6, T7, T8, T9, int)"
0.3,1335255,370,3608.8,3328.0,2752,4608,775.9,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_put_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIterator &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.2,1254289,370,3390.0,2496.0,2112,5888,1365.4,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 2)]>(int, T3)"
0.2,1100344,127,8664.1,8672.0,7360,9024,150.8,"void at::native::radixSortKVInPlace<(int)-2, (int)-1, (int)16, (int)2, float, long, unsigned int>(at::cuda::detail::TensorInfo<T5, T7>, T7, T7, T7, at::cuda::detail::TensorInfo<T6, T7>, T7, bool)"
0.2,1078588,378,2853.4,2752.5,2560,3265,243.9,"void at::native::<unnamed>::upsample_nearest2d_out_frame<c10::Half, &at::native::nearest_neighbor_compute_source_index>(const T1 *, T1 *, unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, float, float)"
0.2,1078069,370,2913.7,2703.5,1920,4096,942.0,"void at_cuda_detail::cub::DeviceReduceSingleTileKernel<at_cuda_detail::cub::DeviceReducePolicy<bool, int, int, at_cuda_detail::cub::Sum>::Policy600, at_cuda_detail::cub::TransformInputIterator<bool, at::native::<unnamed>::NonZeroOp<bool>, bool *, long>, int *, int, at_cuda_detail::cub::Sum, int>(T2, T3, T4, T5, T6)"
0.2,1060340,567,1870.1,1728.0,1536,2400,261.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.2,1000288,567,1764.2,1664.0,1536,2176,184.1,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::pow_tensor_scalar_kernel_impl<c10::Half, c10::Half>(at::TensorIteratorBase &, T2)::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.2,987414,15,65827.6,65791.0,23136,136766,33270.8,cudnn_volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1
0.2,960307,548,1752.4,1696.5,1439,2272,235.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.2,874909,185,4729.2,4704.0,4000,4992,97.5,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<void at::native::compare_scalar_kernel<c10::Half>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(c10::Half) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.2,843578,185,4559.9,4545.0,3104,4736,128.9,"void at_cuda_detail::cub::DeviceSelectSweepKernel<at_cuda_detail::cub::DispatchSelectIf<const float *, at_cuda_detail::cub::NullType *, float *, long *, at_cuda_detail::cub::NullType, at_cuda_detail::cub::Equality, int, (bool)0>::PtxSelectIfPolicyT, const float *, at_cuda_detail::cub::NullType *, float *, long *, at_cuda_detail::cub::ScanTileState<int, (bool)1>, at_cuda_detail::cub::NullType, at_cuda_detail::cub::Equality, int, (bool)0>(T2, T3, T4, T5, T6, T7, T8, T9, int)"
0.2,841689,330,2550.6,2976.0,1887,3296,553.4,"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithCast<(int)1>, at::native::memory::StoreWithCast<(int)1>>(int, T1, T2, T3, T4, T5, T6)"
0.2,806615,328,2459.2,2688.0,2047,2911,338.1,"void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.2,805369,330,2440.5,3008.0,1599,3361,721.0,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<long>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(long) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.2,802968,185,4340.4,4320.0,3648,4608,114.9,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void at::native::index_kernel_impl<at::native::OpaqueType<(int)8>>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>)::[lambda(char *, char *, long) (instance 1)]>(at::TensorIteratorBase &, c10::ArrayRef<long>, c10::ArrayRef<long>, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,769857,189,4073.3,4032.0,3712,4800,184.3,"void at::native::<unnamed>::CatArrayBatchedCopy<c10::Half, unsigned int, (int)3, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
0.1,661180,185,3573.9,3552.0,2752,3872,97.2,"void at::native::vectorized_elementwise_kernel<(int)4, void at::native::compare_scalar_kernel<c10::Half>(at::TensorIteratorBase &, at::native::<unnamed>::OpType, T1)::[lambda(c10::Half) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,652601,58,11251.7,11248.0,9248,11584,289.1,"void at::native::radixSortKVInPlace<(int)-2, (int)-1, (int)32, (int)4, float, long, unsigned int>(at::cuda::detail::TensorInfo<T5, T7>, T7, T7, T7, at::cuda::detail::TensorInfo<T6, T7>, T7, bool)"
0.1,624606,217,2878.4,2688.0,2335,3617,310.8,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,575383,178,3232.5,3264.0,2945,3424,99.3,"void at::native::<unnamed>::indexSelectLargeIndex<float, long, unsigned int, (int)2, (int)2, (int)-2, (bool)1>(at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T2, T3>, int, int, T3, T3, long)"
0.1,561091,370,1516.5,1536.0,1344,1824,148.0,"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, (bool)1>, int *>(T1, int, T2)"
0.1,557527,183,3046.6,3072.0,2400,3232,116.0,"void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::flip_kernel_impl<at::native::OpaqueType<(int)4>>(at::TensorIterator &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,531678,207,2568.5,1760.0,1535,69183,6781.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<float>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.1,520415,185,2813.1,2912.0,2463,3360,184.4,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,505854,183,2764.2,2687.0,2336,3200,169.4,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,504730,183,2758.1,2657.0,2337,3136,156.5,"void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::round_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)]>(at::TensorIteratorBase &, const T1 &)::[lambda(int) (instance 1)]>(int, T3)"
0.1,424892,3,141630.7,206557.0,11009,207326,113122.3,volta_sgemm_32x128_nn
0.1,373824,185,2020.7,2016.0,1824,2209,38.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float>>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,354623,184,1927.3,1888.0,1695,3232,180.6,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float>>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.1,353148,2,176574.0,176574.0,9440,343708,236363.2,"void implicit_convolve_sgemm<float, float, (int)1024, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, const T2 *, const T2 *, bool, int, int)"
0.1,352033,182,1934.2,1408.0,1312,24192,2378.7,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<float>, at::detail::Array<char *, (int)1>>(int, T2, T3)"
0.1,320417,178,1800.1,1760.0,1664,3104,170.8,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::sqrt_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 2)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.1,314843,185,1701.9,1696.0,1536,1856,36.5,"void <unnamed>::elementwise_kernel_with_index<int, at::native::arange_cuda_out(const c10::Scalar &, const c10::Scalar &, const c10::Scalar &, at::Tensor &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 4)]::operator ()() const::[lambda(long) (instance 1)]>(T1, T2, function_traits<T2>::result_type *)"
0.1,306474,185,1656.6,1664.0,1505,1824,32.9,"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, (bool)1>, long *>(T1, int, T2)"
0.1,282941,33,8574.0,7424.0,6143,17087,3216.5,volta_sgemm_32x32_sliced1x4_nn
0.0,264089,73,3617.7,3135.0,2656,12256,1630.4,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,221278,4,55319.5,59839.5,25952,75647,23783.3,"void implicit_convolve_sgemm<float, float, (int)128, (int)5, (int)5, (int)3, (int)3, (int)3, (int)1, (bool)0, (bool)0, (bool)1>(int, int, int, const T1 *, int, T2 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, const T2 *, const T2 *, bool, int, int)"
0.0,219483,19,11551.7,8959.0,6559,34975,8346.2,volta_sgemm_64x32_sliced1x4_nn
0.0,172184,92,1871.6,1824.0,1727,2432,140.9,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, at::detail::Array<char *, (int)3>>(int, T2, T3)"
0.0,164001,15,10933.4,9056.0,3840,36416,10075.4,"void cudnn::winograd::generateWinogradTilesKernel<(int)0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<T2, T3>)"
0.0,143042,36,3973.4,2944.0,2112,9087,2287.9,"void splitKreduce_kernel<(int)32, (int)16, int, float, float, float, float, (bool)1, (bool)0, (bool)0>(cublasSplitKParams<T6>, const T4 *, const T5 *, T5 *, const T6 *, const T6 *, const T7 *, const T4 *, T7 *, void *, long, T6 *, int *)"
0.0,132703,1,132703.0,132703.0,132703,132703,0.0,cudnn_volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1
0.0,100093,49,2042.7,1920.0,1760,2624,245.0,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::silu_kernel(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,76927,1,76927.0,76927.0,76927,76927,0.0,"void precomputed_convolve_sgemm<float, (int)1024, (int)5, (int)5, (int)4, (int)3, (int)3, (int)1, (bool)0>(int, int, int, const T1 *, int, T1 *, const T1 *, kernel_conv_params, unsigned long long, int, float, float, int, bool, const T1 *, const T1 *, int *)"
0.0,67711,1,67711.0,67711.0,67711,67711,0.0,volta_sgemm_128x64_nn
0.0,64641,9,7182.3,6592.0,3840,11680,2547.8,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)4, (int)4, (bool)0, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,60030,7,8575.7,8928.0,7296,9280,885.1,"void at::native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, (int)2, (int)2, (int)-2>(at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T1, T3>, at::cuda::detail::TensorInfo<T2, T3>, int, int, T3, long)"
0.0,32225,9,3580.6,3584.0,3264,4096,299.4,"void at::native::<unnamed>::CatArrayBatchedCopy<float, unsigned int, (int)4, (int)128, (int)1>(T1 *, at::native::<unnamed>::CatArrInputTensorMetadata<T1, T2, T4, T5>, at::native::<unnamed>::TensorSizeStride<T2, (unsigned int)4>, int, T2)"
0.0,29859,12,2488.3,2432.5,2368,2976,162.0,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)2, (int)2, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,21024,6,3504.0,3648.0,2496,4352,815.3,"void at::native::<unnamed>::max_pool_forward_nchw<float, float>(int, const T1 *, long, long, long, int, int, int, int, int, int, int, int, int, int, T1 *, long *)"
0.0,16128,4,4032.0,4032.0,3263,4801,887.4,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<T1, T2>)"
0.0,14304,4,3576.0,3552.0,3264,3936,346.0,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<T1, T2>)"
0.0,14303,4,3575.8,3295.5,3264,4448,581.7,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<T1, T2>)"
0.0,14111,1,14111.0,14111.0,14111,14111,0.0,volta_fp16_s884gemm_fp16_64x128_ldg8_f2f_nn
0.0,12512,2,6256.0,6256.0,2784,9728,4910.1,"void cudnn::ops::nchwToNhwcKernel<float, float, float, (bool)0, (bool)1, (cudnnKernelDataType_t)0>(cudnn::ops::nchw2nhwc_params_t<T3>, const T1 *, T2 *)"
0.0,10625,2,5312.5,5312.5,4545,6080,1085.4,"void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::MaxNanFunctor<float>>, unsigned int, float, (int)4>>(T3)"
0.0,8992,1,8992.0,8992.0,8992,8992,0.0,void cutlass::Kernel<cutlass_70_wmma_tensorop_s161616gemm_f16_32x32_64x2_nn_align8>(T1::Params)
0.0,8512,1,8512.0,8512.0,8512,8512,0.0,"std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, float, float, float, float, (bool)0, (bool)1, (bool)1, (bool)0, (int)8, (bool)0, cublasGemvParamsEx<int, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13)"
0.0,7487,4,1871.8,1824.0,1599,2240,267.4,"void at::native::unrolled_elementwise_kernel<at::native::<unnamed>::launch_clamp_scalar(at::TensorIteratorBase &, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>, TrivialOffsetCalculator<(int)1, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)"
0.0,4832,2,2416.0,2416.0,2112,2720,429.9,"void at::native::vectorized_elementwise_kernel<(int)2, at::native::<unnamed>::launch_clamp_scalar(at::TensorIteratorBase &, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,4734,2,2367.0,2367.0,2079,2655,407.3,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::launch_clamp_scalar(at::TensorIteratorBase &, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 7)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,3680,2,1840.0,1840.0,1696,1984,203.6,"void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, bool, at::native::<unnamed>::CompareEqFunctor<float>>, at::detail::Array<char *, (int)3>, TrivialOffsetCalculator<(int)2, unsigned int>, TrivialOffsetCalculator<(int)1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, T1, T2, T3, T4, T5, T6)"
0.0,3680,2,1840.0,1840.0,1728,1952,158.4,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float>>, at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,3680,2,1840.0,1840.0,1696,1984,203.6,"void at::native::vectorized_elementwise_kernel<(int)4, at::native::round_kernel_cuda(at::TensorIteratorBase &)::[lambda() (instance 1)]::operator ()() const::[lambda() (instance 2)]::operator ()() const::[lambda(float) (instance 1)], at::detail::Array<char *, (int)2>>(int, T2, T3)"
0.0,3296,1,3296.0,3296.0,3296,3296,0.0,"void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)2, (int)4, (bool)0, (bool)0, cublasGemvParams<cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<const float>, cublasGemvTensorStridedBatched<float>, float>>(T13, T6, T6)"
0.0,3168,1,3168.0,3168.0,3168,3168,0.0,"void cudnn::ops::nhwcToNchwKernel<float, float, float, (bool)1, (bool)0, (cudnnKernelDataType_t)0>(cudnn::ops::nhwc2nchw_params_t<T3>, const T1 *, T2 *)"
0.0,2720,1,2720.0,2720.0,2720,2720,0.0,"void splitKreduce_kernel<(int)32, (int)16, int, float, __half, float, __half, (bool)1, (bool)0, (bool)0>(cublasSplitKParams<T6>, const T4 *, const T5 *, T5 *, const T6 *, const T6 *, const T7 *, const T4 *, T7 *, void *, long, T6 *, int *)"
0.0,2111,1,2111.0,2111.0,2111,2111,0.0,"void cask_cudnn::computeOffsetsKernel<(bool)0, (bool)0>(cask_cudnn::ComputeOffsetsParams)"
0.0,1760,1,1760.0,1760.0,1760,1760,0.0,"void cudnn::cnn::kern_precompute_indices<(bool)0>(int *, int, int, int, int, int)"
